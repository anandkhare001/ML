{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40f4fa56-1564-4eb5-8bbb-cbca1f304e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf64a264-2d26-4fc6-85f5-c761beacb5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a7c451d9-1e53-4793-8829-cf78dc8f719d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create an Assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Document Parser\",\n",
    "    instructions=\"You are an assistant to parser web and show details asked.\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=[{\"type\": \"file_search\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "882e7ccb-c9d1-4f94-ba8d-cfa9002381f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Assistant(id='asst_d5Ub9Zyvlg3FYuyF6j2TZzpI', created_at=1717603343, description=None, instructions='You are an assistant to parser web and show details asked.', metadata={}, model='gpt-3.5-turbo', name='Web Parser', object='assistant', tools=[FileSearchTool(type='file_search', file_search=None)], response_format='auto', temperature=1.0, tool_resources=ToolResources(code_interpreter=None, file_search=ToolResourcesFileSearch(vector_store_ids=[])), top_p=1.0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0f3e247-5a5e-48fc-ba01-26ef8d74aea1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<_io.BufferedReader name='Welcome to our extensive MLOps Bootcamp.pdf'>]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store = client.beta.vector_stores.create(name=\"Course Contents\")\n",
    "\n",
    "# Ready the files for upload to OpenAI\n",
    "file_paths = [\"Welcome to our extensive MLOps Bootcamp.pdf\"]\n",
    "file_streams = [open(path, \"rb\") for path in file_paths]\n",
    "file_streams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cae457ef-e98e-4557-8ee8-4120c17360b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed\n",
      "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
     ]
    }
   ],
   "source": [
    "# Use the upload and poll SDK helper to upload the files, add them to the vector store,\n",
    "# and poll the status of the file batch for completion.\n",
    "file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id=vector_store.id, files=file_streams\n",
    ")\n",
    "\n",
    "# You can print the status and the file counts of the batch to see the result of this operation.\n",
    "print(file_batch.status)\n",
    "print(file_batch.file_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f4f66b8b-bb19-4605-bf87-2a45ea104c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'vs_BrlqHc9YnLA0OvIxRk0vS13h'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec1573a0-3396-4814-8bfc-89c3f5e385b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Update the assistant to use the new Vector Store\n",
    "assistant = client.beta.assistants.update(\n",
    "  assistant_id=assistant.id,\n",
    "  tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "86bb49ed-051f-48b5-ae9b-f80f56ac81a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-zvyIhX69z4I9op9C35v2FCP3', bytes=350109, created_at=1717603471, filename='Welcome to our extensive MLOps Bootcamp.pdf', object='file', purpose='assistants', status='processed', status_details=None)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Create a thread\n",
    "# Upload the user provided file to OpenAI\n",
    "message_file = client.files.create(\n",
    "    file=open(\"Welcome to our extensive MLOps Bootcamp.pdf\", \"rb\"), purpose=\"assistants\"\n",
    ")\n",
    "message_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "79141bab-dcd7-4317-95e3-906a5db9abcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ToolResourcesFileSearch(vector_store_ids=['vs_2GzRQNtaJmh9b92flCm0wDNL'])\n"
     ]
    }
   ],
   "source": [
    "# Create a thread and attach the file to the message\n",
    "thread = client.beta.threads.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Display course contents\",\n",
    "            # Attach the new file to the message.\n",
    "            \"attachments\": [\n",
    "                {\"file_id\": message_file.id, \"tools\": [{\"type\": \"file_search\"}]}\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "# The thread now has a vector store with that file in its tool resources.\n",
    "print(thread.tool_resources.file_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f57b345-625e-4035-9043-3ec63f3c3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the create and poll SDK helper to create a run and poll the status of\n",
    "# the run until it's in a terminal state.\n",
    "\n",
    "run = client.beta.threads.runs.create_and_poll(\n",
    "    thread_id=thread.id, assistant_id=assistant.id\n",
    ")\n",
    "\n",
    "messages = list(client.beta.threads.messages.list(thread_id=thread.id, run_id=run.id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cb281ada-be81-4891-ae59-cf644908c76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(id='run_6vbyCw2m5ZiXJ3nlmNFeNFsf', assistant_id='asst_oPTOTJvfOc5As77zdD2uXB02', cancelled_at=None, completed_at=None, created_at=1717603478, expires_at=None, failed_at=1717603483, incomplete_details=None, instructions='You are an assistant to parser web and show details asked.', last_error=LastError(code='rate_limit_exceeded', message='You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.'), max_completion_tokens=None, max_prompt_tokens=None, metadata={}, model='gpt-3.5-turbo', object='thread.run', required_action=None, response_format='auto', started_at=1717603478, status='failed', thread_id='thread_2yd643MOsRrKVSzc03O6ea8E', tool_choice='auto', tools=[FileSearchTool(type='file_search', file_search=None)], truncation_strategy=TruncationStrategy(type='auto', last_messages=None), usage=Usage(completion_tokens=0, prompt_tokens=0, total_tokens=0), temperature=1.0, top_p=1.0, tool_resources={})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57b10265-c56d-47fc-9217-348ed44d2b55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "29877292-4a5c-4f79-be78-1bc449ce6bd7",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m message_content \u001b[38;5;241m=\u001b[39m \u001b[43mmessages\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mcontent[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m      2\u001b[0m annotations \u001b[38;5;241m=\u001b[39m message_content\u001b[38;5;241m.\u001b[39mannotations\n\u001b[0;32m      3\u001b[0m citations \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "message_content = messages[0].content[0].text\n",
    "annotations = message_content.annotations\n",
    "citations = []\n",
    "for index, annotation in enumerate(annotations):\n",
    "    message_content.value = message_content.value.replace(annotation.text, f\"[{index}]\")\n",
    "    if file_citation := getattr(annotation, \"file_citation\", None):\n",
    "        cited_file = client.files.retrieve(file_citation.file_id)\n",
    "        citations.append(f\"[{index}] {cited_file.filename}\")\n",
    "\n",
    "print(message_content.value)\n",
    "print(\"\\n\".join(citations))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f0eed4-8d6a-47c3-bce5-0f01c08a86de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
